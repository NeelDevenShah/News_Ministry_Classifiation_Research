{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4598,"sourceType":"datasetVersion","datasetId":2773},{"sourceId":6360331,"sourceType":"datasetVersion","datasetId":3663765},{"sourceId":6442911,"sourceType":"datasetVersion","datasetId":3718728},{"sourceId":6503901,"sourceType":"datasetVersion","datasetId":3759852},{"sourceId":7218606,"sourceType":"datasetVersion","datasetId":4172905}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><b>Ministry Classification Model</b></h1>\n\n<h3>We will be only considering the first 550 character of the (title + content) for our prediction, Due to the computational limitation</h3>","metadata":{}},{"cell_type":"markdown","source":"<h2>\n<h2>TODO</h2>\n<ul>\n<li>Padding length is to be set, According to the result wanted, Currently padding length is seted to the `550`.</li>    \n</ul>\n</h2>","metadata":{}},{"cell_type":"markdown","source":"<h1>Process 1: Importing the Libraries</h1>","metadata":{}},{"cell_type":"code","source":"# For basic dataframe and mathematical operations\nimport numpy as np\nimport pandas as pd\n\n# For Deep Learning Model\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\n\n# For natural language processing\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\n# For utility\nimport re\n# import lgging\nimport time\nimport pickle\nimport itertools\n","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:09:54.437422Z","iopub.execute_input":"2023-12-17T16:09:54.438325Z","iopub.status.idle":"2023-12-17T16:09:54.444818Z","shell.execute_reply.started":"2023-12-17T16:09:54.438290Z","shell.execute_reply":"2023-12-17T16:09:54.443531Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"<h2>Processs 2: Code for configuring multiple GPUs</h2>","metadata":{}},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:09:54.450262Z","iopub.execute_input":"2023-12-17T16:09:54.450596Z","iopub.status.idle":"2023-12-17T16:09:54.458120Z","shell.execute_reply.started":"2023-12-17T16:09:54.450569Z","shell.execute_reply":"2023-12-17T16:09:54.456995Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 7110176208523214213\nxla_global_id: -1\n]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h1>Process 3: Making press release dataset ready for giving it as input to classification model</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2>Managining new 61th i.e. no ministry labeled datatset for classification model</h2>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/indian-news-dataset-with-ministry-labels/combined_dataset.csv\", encoding='unicode_escape')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:09:54.459711Z","iopub.execute_input":"2023-12-17T16:09:54.460392Z","iopub.status.idle":"2023-12-17T16:09:54.836393Z","shell.execute_reply.started":"2023-12-17T16:09:54.460354Z","shell.execute_reply":"2023-12-17T16:09:54.835015Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"markdown","source":"<h2>Managing press release dataset</h2>","metadata":{}},{"cell_type":"markdown","source":"<h2>List of the ministry and it's specific index number</h2>\n<ul>\n<li> 0 Ministry of Railways </li>\n<li> 1 Ministry of Rural Development </li>\n<li> 2 Ministry of Steel </li>\n<li> 3 Ministry of Science & Technology </li>\n<li> 4 Ministry of Information & Broadcasting </li>\n<li> 5 Ministry of Food Processing Industries </li>\n<li> 6 Ministry of Health and Family Welfare </li>\n<li> 7 Ministry of Human Resource Development </li>\n<li> 8 Ministry of Agriculture </li>\n<li> 9 Ministry of Environment and Forests </li>\n<li> 10 Ministry of Chemicals and Fertilizers </li>\n<li> 11 Ministry of Water Resources </li>\n<li> 12 Ministry of Defence </li>\n<li> 13 Ministry of Petroleum & Natural Gas </li>\n<li> 14 President's Secretariat </li>\n<li> 15 Ministry of Micro,Small & Medium Enterprises </li>\n<li> 16 Ministry of Mines </li>\n<li> 17 Ministry of Tourism </li>\n<li> 18 Ministry of Housing & Urban Affairs </li>\n<li> 19 Ministry of Coal </li>\n<li> 20 Prime Minister's Office </li>\n<li> 21 Ministry of Textiles </li>\n<li> 22 Ministry of Commerce & Industry </li>\n<li> 23 Ministry of External Affairs </li>\n<li> 24 Ministry of Social Justice & Empowerment </li>\n<li> 25 Ministry of Power </li>\n<li> 26 Ministry of Consumer Affairs, Food & Public Distribution </li>\n<li> 27 Ministry of Heavy Industries & Public Enterprises </li>\n<li> 28 Ministry of Communications </li>\n<li> 29 Ministry of Shipping </li>\n<li> 30 Ministry of Finance </li>\n<li> 31 Ministry of Tribal Affairs </li>\n<li> 32 Ministry of Statistics & Programme Implementation </li>\n<li> 33 Ministry of Labour & Employment </li>\n<li> 34 Ministry of Law & Justice </li>\n<li> 35 Vice President's Secretariat </li>\n<li> 36 Ministry of Civil Aviation </li>\n<li> 37 Ministry for Development of North-East Region </li>\n<li> 38 UPSC </li>\n<li> 39 Ministry of Agro & Rural Industries </li>\n<li> 40 Ministry of Home Affairs </li>\n<li> 41 Ministry of Youth Affairs and Sports </li>\n<li> 42 Special Service and Features </li>\n<li> 43 Ministry of New and Renewable Energy </li>\n<li> 44 Ministry of Parliamentary Affairs </li>\n<li> 45 Planning Commission </li>\n<li> 46 Ministry of Personnel, Public Grievances & Pensions </li>\n<li> 47 Election Commission </li>\n<li> 48 Department of Space </li>\n<li> 49 Ministry of Disinvestment </li>\n<li> 50 Department of Ocean Development </li>\n<li> 51 Ministry of Overseas Indian Affairs </li>\n<li> 52 Ministry of Housing and Urban Poverty Alleviation </li>\n<li> 53 Ministry of Culture </li>\n<li> 54 Ministry of Company Affairs </li>\n<li> 55 Ministry of Panchayati Raj </li>\n<li> 56 Cabinet Committee on Economic Affairs (CCEA) </li>\n<li> 57 Cabinet </li>\n<li> 58 Department of Atomic Energy </li>\n<li> 59 Cabinet Committee Decisions </li>\n<li>60 No Ministry</li>\n</ul>","metadata":{}},{"cell_type":"markdown","source":"<b>Mapping the ministry to the it's index number starting from the 1 and `0` is made reserved for the `Not Ministry`, If any news doesn't belongs to any ministry of our current ministry dataset, So total labels are `59+1(no ministry)`</b>","metadata":{}},{"cell_type":"markdown","source":"<h3>Making the cocatination of the pr_title and pr_content in the new field named content</h3>","metadata":{}},{"cell_type":"code","source":"tmp =  df.labels.isnull()\nfor idx, val in enumerate(tmp):\n    if val == True:\n        print(df['news_num'][idx], df['labels'][idx], df['content'][idx])\n        print('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:09:54.837664Z","iopub.execute_input":"2023-12-17T16:09:54.837995Z","iopub.status.idle":"2023-12-17T16:09:54.862020Z","shell.execute_reply.started":"2023-12-17T16:09:54.837965Z","shell.execute_reply":"2023-12-17T16:09:54.860587Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"for i in range(len(df)):       \n    if pd.isnull(df.loc[i, 'title']):\n        df.loc[i, 'content'] = str(df.loc[i, 'content'])[:550]\n    elif pd.isnull(df.loc[i, 'content']):\n        df.loc[i, 'content'] = str(df.loc[i, 'title'])[:550]\n    else:\n        df.loc[i, 'content'] = (str(df.loc[i, 'title']) + \" \" + str(df.loc[i, 'content']))[:550]\ndf.drop(columns=['news_num', 'title'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:09:54.865128Z","iopub.execute_input":"2023-12-17T16:09:54.865881Z","iopub.status.idle":"2023-12-17T16:10:13.455002Z","shell.execute_reply.started":"2023-12-17T16:09:54.865836Z","shell.execute_reply":"2023-12-17T16:10:13.453788Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.456204Z","iopub.execute_input":"2023-12-17T16:10:13.456814Z","iopub.status.idle":"2023-12-17T16:10:13.467594Z","shell.execute_reply.started":"2023-12-17T16:10:13.456782Z","shell.execute_reply":"2023-12-17T16:10:13.466597Z"},"trusted":true},"execution_count":130,"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"  labels                                            content\n0      0  Trainer aircraft crashes in Odisha, 2 killed A...\n1     17  Uttarkhand unlock 1.0: Hotel bookings for mini...\n2     12  J-K: Four Hizbul militants killed in Shopian e...\n3  54,33  Mumbai offices to reopen today, with curbs Pri...\n4     12  PDP, NC, PC call for release of all J&K leader...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Trainer aircraft crashes in Odisha, 2 killed A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Uttarkhand unlock 1.0: Hotel bookings for mini...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>J-K: Four Hizbul militants killed in Shopian e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54,33</td>\n      <td>Mumbai offices to reopen today, with curbs Pri...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>PDP, NC, PC call for release of all J&amp;K leader...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<h2>Concatinating press release and 0 label dataset</h2>","metadata":{}},{"cell_type":"code","source":"# df = pd.concat([df, df4, df5, df6], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.469108Z","iopub.execute_input":"2023-12-17T16:10:13.470116Z","iopub.status.idle":"2023-12-17T16:10:13.478257Z","shell.execute_reply.started":"2023-12-17T16:10:13.470075Z","shell.execute_reply":"2023-12-17T16:10:13.477009Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"# df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.479790Z","iopub.execute_input":"2023-12-17T16:10:13.480136Z","iopub.status.idle":"2023-12-17T16:10:13.490156Z","shell.execute_reply.started":"2023-12-17T16:10:13.480105Z","shell.execute_reply":"2023-12-17T16:10:13.489241Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"# df.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.491577Z","iopub.execute_input":"2023-12-17T16:10:13.492466Z","iopub.status.idle":"2023-12-17T16:10:13.500646Z","shell.execute_reply.started":"2023-12-17T16:10:13.492434Z","shell.execute_reply":"2023-12-17T16:10:13.499355Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"markdown","source":"<h3>Shuffling Dataframe</h3>","metadata":{}},{"cell_type":"code","source":"# df = df.sample(frac = 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.504700Z","iopub.execute_input":"2023-12-17T16:10:13.505031Z","iopub.status.idle":"2023-12-17T16:10:13.511488Z","shell.execute_reply.started":"2023-12-17T16:10:13.505003Z","shell.execute_reply":"2023-12-17T16:10:13.510191Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"<h2>Preprocessing and Lemmatizing the text, So that makning the text to the it's base form. So that there would be no repetation allotment of the same keyword in the different state</h2>","metadata":{}},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.515017Z","iopub.execute_input":"2023-12-17T16:10:13.515379Z","iopub.status.idle":"2023-12-17T16:10:13.525576Z","shell.execute_reply.started":"2023-12-17T16:10:13.515348Z","shell.execute_reply":"2023-12-17T16:10:13.524457Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = stopwords.words(\"english\")\nstemmer = SnowballStemmer(\"english\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.527567Z","iopub.execute_input":"2023-12-17T16:10:13.527977Z","iopub.status.idle":"2023-12-17T16:10:13.534129Z","shell.execute_reply.started":"2023-12-17T16:10:13.527939Z","shell.execute_reply":"2023-12-17T16:10:13.533046Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"def preprocess(text, stem=False):\n    # Removing link, user, special characters\n    test = re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', str(text).lower()).strip()\n    tokens = []\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return \" \".join(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.535647Z","iopub.execute_input":"2023-12-17T16:10:13.536068Z","iopub.status.idle":"2023-12-17T16:10:13.548415Z","shell.execute_reply.started":"2023-12-17T16:10:13.536028Z","shell.execute_reply":"2023-12-17T16:10:13.547203Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"for i in range(len(df)):\n    df.loc[i, 'content'] = preprocess(df.loc[i, 'content'], True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:10:13.550026Z","iopub.execute_input":"2023-12-17T16:10:13.550442Z","iopub.status.idle":"2023-12-17T16:11:13.053208Z","shell.execute_reply.started":"2023-12-17T16:10:13.550404Z","shell.execute_reply":"2023-12-17T16:11:13.051951Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":"<h1>Doing OneHot encoding of the labels</h2>","metadata":{}},{"cell_type":"code","source":"df['labels'][458]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.054745Z","iopub.execute_input":"2023-12-17T16:11:13.055105Z","iopub.status.idle":"2023-12-17T16:11:13.062375Z","shell.execute_reply.started":"2023-12-17T16:11:13.055074Z","shell.execute_reply":"2023-12-17T16:11:13.061325Z"},"trusted":true},"execution_count":139,"outputs":[{"execution_count":139,"output_type":"execute_result","data":{"text/plain":"'6,7'"},"metadata":{}}]},{"cell_type":"code","source":"# def convert_to_int_list(x):\n#     try:\n#         return [int(value) for value in x.split(',') if value]\n#     except ValueError:\n#         return []\n\n\n# tmp_label_list = df['labels'].apply(convert_to_int_list)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.063742Z","iopub.execute_input":"2023-12-17T16:11:13.064149Z","iopub.status.idle":"2023-12-17T16:11:13.073515Z","shell.execute_reply.started":"2023-12-17T16:11:13.064119Z","shell.execute_reply":"2023-12-17T16:11:13.072239Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"# tmp_label_list[3]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.076053Z","iopub.execute_input":"2023-12-17T16:11:13.077012Z","iopub.status.idle":"2023-12-17T16:11:13.083509Z","shell.execute_reply.started":"2023-12-17T16:11:13.076967Z","shell.execute_reply":"2023-12-17T16:11:13.082675Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"<h2>Making the custom one hot labeling function as per the requriement</h2>","metadata":{}},{"cell_type":"code","source":"# def make_one_hot_encoding(num_ministries, tmp_label_list):\n#     outer_list = []\n\n#     for i in range(len(tmp_label_list)):\n#         inner_list = [0]*num_ministries\n#         for j in tmp_label_list[i]:\n#             inner_list[j] = 1\n#         outer_list.append(inner_list)\n#     return outer_list","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.084639Z","iopub.execute_input":"2023-12-17T16:11:13.085485Z","iopub.status.idle":"2023-12-17T16:11:13.093948Z","shell.execute_reply.started":"2023-12-17T16:11:13.085446Z","shell.execute_reply":"2023-12-17T16:11:13.092897Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"# num_classes = 61\n\n# # onehot_labels = make_one_hot_encoding(61, tmp_label_list)\n# onehot_labels = []\n# for label_list in tmp_label_list:\n#     categorical = tf.keras.utils.to_categorical(label_list, num_classes=num_classes)\n#     if len(categorical) >1:\n#         i=0\n#         for list_ in categorical:\n#             if i==0:\n#                 ans = np.asarray(list_.tolist())\n#             else:\n#                 ans = ans + np.asarray(list_.tolist())\n#             i+=1\n#         onehot_labels.append(ans)\n#     else:\n#         onehot_labels.append(np.asarray(categorical.flatten().tolist()))\n\n# onehot_labels = np.asarray(onehot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.095642Z","iopub.execute_input":"2023-12-17T16:11:13.096007Z","iopub.status.idle":"2023-12-17T16:11:13.104680Z","shell.execute_reply.started":"2023-12-17T16:11:13.095978Z","shell.execute_reply":"2023-12-17T16:11:13.103596Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"def convert_to_multi_one_hot(df, label_col, num_classes):\n    \n    # Split labels by comma  \n    labels = df[label_col].apply(lambda x: x.split(\",\")).values\n    # Initialize one-hot encoding array  \n    one_hot = np.zeros((len(labels), num_classes))\n    for i, label_vals in enumerate(labels):\n        # Clean individual values\n        cleaned = [] \n        for l in label_vals:\n            l = l.strip().rstrip(\".\") # Strip whitespace and periods\n            try:\n                index = int(l) # Attempt integer conversion\n                cleaned.append(index) \n            except ValueError: \n                print(f\"Skipping invalid label value {l}\")\n                pass # Skip invalid values\n                \n            # Set encoding from cleaned values\n            indices = [int(l) for l in cleaned]  \n            one_hot[i, indices] = 1 \n    return one_hot\n\nonehot_labels = convert_to_multi_one_hot(df, \"labels\", 61)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:20:41.497387Z","iopub.execute_input":"2023-12-17T16:20:41.497864Z","iopub.status.idle":"2023-12-17T16:20:41.760697Z","shell.execute_reply.started":"2023-12-17T16:20:41.497827Z","shell.execute_reply":"2023-12-17T16:20:41.759219Z"},"trusted":true},"execution_count":170,"outputs":[{"name":"stdout","text":"Skipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value 41`\n","output_type":"stream"}]},{"cell_type":"code","source":"print(onehot_labels[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:20:50.957872Z","iopub.execute_input":"2023-12-17T16:20:50.958255Z","iopub.status.idle":"2023-12-17T16:20:50.964217Z","shell.execute_reply.started":"2023-12-17T16:20:50.958225Z","shell.execute_reply":"2023-12-17T16:20:50.963209Z"},"trusted":true},"execution_count":172,"outputs":[{"name":"stdout","text":"[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","output_type":"stream"}]},{"cell_type":"code","source":"onehot_labels[3]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:20:53.466758Z","iopub.execute_input":"2023-12-17T16:20:53.467142Z","iopub.status.idle":"2023-12-17T16:20:53.474844Z","shell.execute_reply.started":"2023-12-17T16:20:53.467113Z","shell.execute_reply":"2023-12-17T16:20:53.473943Z"},"trusted":true},"execution_count":173,"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"markdown","source":"<h2>Tokenising Text</h2>","metadata":{}},{"cell_type":"code","source":"tokenizer = keras.preprocessing.text.Tokenizer(oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(df.content)\n\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Total Words\", vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.291069Z","iopub.status.idle":"2023-12-17T16:11:13.291522Z","shell.execute_reply.started":"2023-12-17T16:11:13.291324Z","shell.execute_reply":"2023-12-17T16:11:13.291344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>For saving the tokenizer</b>","metadata":{}},{"cell_type":"code","source":"# ALREADY COMMENTED FROM BEGINING, THIS PART IS NOT COMMENTED DURING THE DATASET CHANGE\n\n# import json\n\n# # Serialize the tokenizer's configuration to JSON\n# tokenizer_config = tokenizer.to_json()\n\n# # Save the tokenizer configuration to a file\n# with open('tokenizer_config.json', 'w', encoding='utf-8') as json_file:\n#     json.dump(tokenizer_config, json_file, ensure_ascii=False, indent=4)\n\n# # Optionally, save the tokenizer weights to a separate file (e.g., for the embeddings layer)\n# # tokenizer.word_index contains the vocabulary and word-to-index mapping\n# with open('tokenizer_weights.json', 'w', encoding='utf-8') as json_file:\n#     json.dump(tokenizer.word_index, json_file, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.293241Z","iopub.status.idle":"2023-12-17T16:11:13.293822Z","shell.execute_reply.started":"2023-12-17T16:11:13.293536Z","shell.execute_reply":"2023-12-17T16:11:13.293561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>For converting the text to the sequence of tokens</b>","metadata":{}},{"cell_type":"code","source":"tokenized_train_text = tokenizer.texts_to_sequences(df.content)\n# tokenized_train_text = same for test","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.295312Z","iopub.status.idle":"2023-12-17T16:11:13.295845Z","shell.execute_reply.started":"2023-12-17T16:11:13.295567Z","shell.execute_reply":"2023-12-17T16:11:13.295592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2><b>Currently setting the the padding length to be equal to the maxlength of the content, But in the applciacation one length have to be made fixed for this pupose, if cotent is more than that then the content will be croped</b></h2>\n\n<b>OR</b>\n\n<h2>\n<b>\n    One have to change the input layer dimension of the model, during the inference time\n</b>\n<h2>\n<b>It is remaining to make the test dataset, And by help of the padding make sure in it that the input size is same as that of the input layer, otherwise it will give an error</b>","metadata":{}},{"cell_type":"markdown","source":"<b>Finding the max length of the content from the dataset, To make it the height text or sequence length for all of one, So that the input would have the same dimensions by help of the padding</b>","metadata":{}},{"cell_type":"code","source":"# max_sequence_len_tmp = max([len(x) for x in df.content])\nmax_sequence_len_tmp = 550 # As per the EDA report of the dataset by Neel Shah","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.297978Z","iopub.status.idle":"2023-12-17T16:11:13.298536Z","shell.execute_reply.started":"2023-12-17T16:11:13.298265Z","shell.execute_reply":"2023-12-17T16:11:13.298292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>TODO: Also check for the pre</h2>","metadata":{}},{"cell_type":"code","source":"x_train = keras.preprocessing.sequence.pad_sequences(tokenized_train_text, maxlen=max_sequence_len_tmp, truncating='post',)\n# x_test = same for test as of train","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.299954Z","iopub.status.idle":"2023-12-17T16:11:13.300492Z","shell.execute_reply.started":"2023-12-17T16:11:13.300222Z","shell.execute_reply":"2023-12-17T16:11:13.300249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train[2]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.302222Z","iopub.status.idle":"2023-12-17T16:11:13.302848Z","shell.execute_reply.started":"2023-12-17T16:11:13.302530Z","shell.execute_reply":"2023-12-17T16:11:13.302556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"next, to do label encdcoder, whicg encodes the value betn 0 and 1, but ","metadata":{}},{"cell_type":"code","source":"# Embedding dimensions to be changed as per the in which highest accuracy is got\nimport tensorflow as tf\n\n# Create a MirroredStrategy to use all available GPUs\nstrategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n\n    model = tf.keras.Sequential([\n        tf.keras.layers.Embedding(vocab_size, 300, input_length=max_sequence_len_tmp),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(61, activation='softmax')\n    ])\n\n    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.0010), metrics=['accuracy'])\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.304526Z","iopub.status.idle":"2023-12-17T16:11:13.305069Z","shell.execute_reply.started":"2023-12-17T16:11:13.304788Z","shell.execute_reply":"2023-12-17T16:11:13.304813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(x_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.306628Z","iopub.status.idle":"2023-12-17T16:11:13.306995Z","shell.execute_reply.started":"2023-12-17T16:11:13.306816Z","shell.execute_reply":"2023-12-17T16:11:13.306833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(onehot_labels[0]), type(onehot_labels[33000])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.308810Z","iopub.status.idle":"2023-12-17T16:11:13.309200Z","shell.execute_reply.started":"2023-12-17T16:11:13.309000Z","shell.execute_reply":"2023-12-17T16:11:13.309017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(onehot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.310561Z","iopub.status.idle":"2023-12-17T16:11:13.310925Z","shell.execute_reply.started":"2023-12-17T16:11:13.310747Z","shell.execute_reply":"2023-12-17T16:11:13.310764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = tf.convert_to_tensor(x_train)\ntype(x_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.311810Z","iopub.status.idle":"2023-12-17T16:11:13.312557Z","shell.execute_reply.started":"2023-12-17T16:11:13.312358Z","shell.execute_reply":"2023-12-17T16:11:13.312377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot_labels[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.313747Z","iopub.status.idle":"2023-12-17T16:11:13.314395Z","shell.execute_reply.started":"2023-12-17T16:11:13.314194Z","shell.execute_reply":"2023-12-17T16:11:13.314219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"C[3]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.315439Z","iopub.status.idle":"2023-12-17T16:11:13.315806Z","shell.execute_reply.started":"2023-12-17T16:11:13.315623Z","shell.execute_reply":"2023-12-17T16:11:13.315640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flat_labels = np.array([np.array(x) for x in onehot_labels])","metadata":{"trusted":true},"execution_count":174,"outputs":[{"execution_count":174,"output_type":"execute_result","data":{"text/plain":"array([array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])                           ,\n       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])                           ,\n       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])                           ,\n       ...,\n       array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])                           ,\n       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])                           ,\n       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n              0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])                           ],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"onehot_labels = tf.convert_to_tensor(onehot_labels, dtype=tf.float32)\n# type(onehot_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:22:14.719964Z","iopub.execute_input":"2023-12-17T16:22:14.722558Z","iopub.status.idle":"2023-12-17T16:22:14.739793Z","shell.execute_reply.started":"2023-12-17T16:22:14.722501Z","shell.execute_reply":"2023-12-17T16:22:14.738631Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"num_epochs = 30\n\nimport tensorflow as tf\n\n# Create a MirroredStrategy to use all available GPUs\nwith strategy.scope():\n    callbacks = [ tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n                  tf.keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]\n    # with single gpu    \n#     history = model.fit(x_train, onehot_labels, batch_size=256, epochs=num_epochs, verbose=1)\n    \n    # with double gpu\n    history = model.fit(x_train, onehot_labels, batch_size=1024, epochs=num_epochs, verbose=1, callbacks=[callbacks])\n    \n    # history = model.fit(x_train, onehot_labels, epochs=num_epochs, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.321572Z","iopub.status.idle":"2023-12-17T16:11:13.322299Z","shell.execute_reply.started":"2023-12-17T16:11:13.321828Z","shell.execute_reply":"2023-12-17T16:11:13.321977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Plotting the accuracy</b>","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# plot utility\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n#     plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, string])\n    #     plt.legend([string, 'val_'+string])\n    plt.show()\n    \ndef plot_val_graphs(history, string):\n    plt.plot(history.history['val_'+string])\n#     plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel('Validation '+string)\n    #     plt.legend([string, 'val_'+string])\n    plt.show()\n    \n# plot the accuracy and results\nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")\n\nplot_val_graphs(history, \"accuracy\")\nplot_val_graphs(history, \"loss\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.324764Z","iopub.status.idle":"2023-12-17T16:11:13.325352Z","shell.execute_reply.started":"2023-12-17T16:11:13.325051Z","shell.execute_reply":"2023-12-17T16:11:13.325076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Saving the weights</h2>","metadata":{}},{"cell_type":"code","source":"KERAS_MODEL = \"model.h5\"\nTOKENIZER_MODEL = \"tokenizer.pkl\"\n    \nmodel.save(KERAS_MODEL)\npickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.327198Z","iopub.status.idle":"2023-12-17T16:11:13.327732Z","shell.execute_reply.started":"2023-12-17T16:11:13.327458Z","shell.execute_reply":"2023-12-17T16:11:13.327483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Testing (Error Will Come With GPU, Try Instead Recreating section, without GPU)</h1>","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    tokenized_test_text = tokenizer.texts_to_sequences([\"EMPHASIS ON USE OF HINDI IN RAILWAYS The Chairman, Railway Board, Shri R.K.Singh ha\"])\n    x_train = keras.preprocessing.sequence.pad_sequences(tokenized_test_text, maxlen=max_sequence_len_tmp)\n    ans = model.predict([x_train])\n    class_labels = ans.argmax(axis=-1)\n    print(ans)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.329109Z","iopub.status.idle":"2023-12-17T16:11:13.329669Z","shell.execute_reply.started":"2023-12-17T16:11:13.329391Z","shell.execute_reply":"2023-12-17T16:11:13.329416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.331782Z","iopub.status.idle":"2023-12-17T16:11:13.332341Z","shell.execute_reply.started":"2023-12-17T16:11:13.332041Z","shell.execute_reply":"2023-12-17T16:11:13.332065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>For recreating the model from weights, Without gpu, As error is comming in gpu (NO GPU)</h1>\nCancelledError                            Traceback (most recent call last)\nCell In[40], line 4\n      2 tokenized_test_text = tokenizer.texts_to_sequences([\"EMPHASIS ON USE OF HINDI IN RAILWAYS The Chairman, Railway Board, Shri R.K.Singh ha\"])\n      3 x_train = keras.preprocessing.sequence.pad_sequences(tokenized_test_text, maxlen=max_sequence_len_tmp)\n----> 4 ans = model.predict([x_train])\n      5 class_labels = ans.argmax(axis=-1)\n      6 print(ans)\n\nFile /opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n\nFile /opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     50 try:\n     51   ctx.ensure_initialized()\n---> 52   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     53                                       inputs, attrs, num_outputs)\n     54 except core._NotOkStatusException as e:\n     55   if name is not None:\n\nCancelledError: Graph execution error:\n\nRecvAsync is cancelled.\n\t [[{{node sequential/dense_1/Softmax/_53}}]] [Op:__inference_predict_function_34609]","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.333828Z","iopub.status.idle":"2023-12-17T16:11:13.334549Z","shell.execute_reply.started":"2023-12-17T16:11:13.334247Z","shell.execute_reply":"2023-12-17T16:11:13.334293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As per last execution during training\nvocab_size = 40310\nmax_sequence_len_tmp = 550\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, 300, input_length=max_sequence_len_tmp),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(61, activation='softmax')\n])  ","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.336299Z","iopub.status.idle":"2023-12-17T16:11:13.336821Z","shell.execute_reply.started":"2023-12-17T16:11:13.336555Z","shell.execute_reply":"2023-12-17T16:11:13.336580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.338599Z","iopub.status.idle":"2023-12-17T16:11:13.339160Z","shell.execute_reply.started":"2023-12-17T16:11:13.338857Z","shell.execute_reply":"2023-12-17T16:11:13.338884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>For loading the pretrained model, And making the prediction</h1>","metadata":{}},{"cell_type":"code","source":"model.load_weights('/kaggle/input/tmp-data/model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.341321Z","iopub.status.idle":"2023-12-17T16:11:13.341851Z","shell.execute_reply.started":"2023-12-17T16:11:13.341575Z","shell.execute_reply":"2023-12-17T16:11:13.341599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_tokenizer():\n    with open('/kaggle/input/tmp-data/tokenizer.pkl', 'rb') as handle:\n        tokenizer = pickle.load(handle)\n\n    print(len(tokenizer.word_index))\n    print('loading of tokenizer completed........')\n\n    return tokenizer\n\ntokenizer = load_tokenizer()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.343021Z","iopub.status.idle":"2023-12-17T16:11:13.343604Z","shell.execute_reply.started":"2023-12-17T16:11:13.343335Z","shell.execute_reply":"2023-12-17T16:11:13.343360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_text = tokenizer.texts_to_sequences([\"Supreme court gives notice to car owner regarding tax dues\"])\nx_train = keras.preprocessing.sequence.pad_sequences(tokenized_test_text, maxlen=max_sequence_len_tmp)\nans = model.predict([x_train])\nprint(ans)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.345984Z","iopub.status.idle":"2023-12-17T16:11:13.346572Z","shell.execute_reply.started":"2023-12-17T16:11:13.346256Z","shell.execute_reply":"2023-12-17T16:11:13.346321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Finding Top 3 probable minstries as per the model's output</h2>","metadata":{}},{"cell_type":"code","source":"# dict_items([('Not Ministry', 61), ('Ministry of Railways', 1), ('Ministry of Rural Development', 2), ('Ministry of Steel', 3), ('Ministry of Science & Technology', 4), ('Ministry of Information & Broadcasting', 5), ('Ministry of Food Processing Industries', 6), ('Ministry of Health and Family Welfare', 7), ('Ministry of Human Resource Development', 8), ('Ministry of Agriculture', 9), ('Ministry of Environment and Forests', 10), ('Ministry of Chemicals and Fertilizers', 11), ('Ministry of Water Resources', 12), ('Ministry of Defence', 13), ('Ministry of Petroleum & Natural Gas', 14), (\"President's Secretariat\", 15), ('Ministry of Micro,Small & Medium Enterprises', 16), ('Ministry of Mines', 17), ('Ministry of Tourism', 18), ('Ministry of Housing & Urban Affairs', 19), ('Ministry of Coal', 20), (\"Prime Minister's Office\", 21), ('Ministry of Textiles', 22), ('Ministry of Commerce & Industry', 23), ('Ministry of External Affairs', 24), ('Ministry of Social Justice & Empowerment', 25), ('Ministry of Power', 26), ('Ministry of Consumer Affairs, Food & Public Distribution', 27), ('Ministry of Heavy Industries & Public Enterprises', 28), ('Ministry of Communications', 29), ('Ministry of Shipping', 30), ('Ministry of Finance', 31), ('Ministry of Tribal Affairs', 32), ('Ministry of Statistics & Programme Implementation', 33), ('Ministry of Labour & Employment', 34), ('Ministry of Law & Justice', 35), (\"Vice President's Secretariat\", 36), ('Ministry of Civil Aviation', 37), ('Ministry for Development of North-East Region', 38), ('UPSC', 39), ('Ministry of Agro & Rural Industries', 40), ('Ministry of Home Affairs', 41), ('Ministry of Youth Affairs and Sports', 42), ('Special Service and Features', 43), ('Ministry of New and Renewable Energy', 44), ('Ministry of Parliamentary Affairs', 45), ('Planning Commission', 46), ('Ministry of Personnel, Public Grievances & Pensions', 47), ('Election Commission', 48), ('Department of Space', 49), ('Ministry of Disinvestment', 50), ('Department of Ocean Development', 51), ('Ministry of Overseas Indian Affairs', 52), ('Ministry of Housing and Urban Poverty Alleviation', 53), ('Ministry of Culture', 54), ('Ministry of Company Affairs', 55), ('Ministry of Panchayati Raj', 56), ('Cabinet Committee on Economic Affairs (CCEA)', 57), ('Cabinet', 58), ('Department of Atomic Energy', 59), ('Cabinet Committee Decisions', 60)])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.348422Z","iopub.status.idle":"2023-12-17T16:11:13.348982Z","shell.execute_reply.started":"2023-12-17T16:11:13.348679Z","shell.execute_reply":"2023-12-17T16:11:13.348705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = ans.argmax(axis=-1)\nprint(class_labels)\ntop_3_labels = np.argsort(ans)[-3:]\nprint(top_3_labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T16:11:13.350101Z","iopub.status.idle":"2023-12-17T16:11:13.350830Z","shell.execute_reply.started":"2023-12-17T16:11:13.350495Z","shell.execute_reply":"2023-12-17T16:11:13.350524Z"},"trusted":true},"execution_count":null,"outputs":[]}]}