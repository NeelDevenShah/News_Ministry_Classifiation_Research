{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7224039,"sourceType":"datasetVersion","datasetId":4172905}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><b>Ministry Classification Model BILSTM + CONVOLUTION</b></h1>\n\n<h3>We will be only considering the first 550 character of the (title + content) for our prediction, Due to the computational limitation</h3>\n<h3>Added call back functionality</h3>\n<h3>Added the validation split</h3>","metadata":{"id":"IrBYyhAgcRsc"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/gdrive')\n\n# from google.colab import files\n\n# files.upload() #this will prompt you to upload the kaggle.json\n\n# !ls -lha kaggle.json\n\n# !pip install -q kaggle\n\n# !mkdir -p ~/.kaggle\n# !cp kaggle.json ~/.kaggle/\n\n# !chmod 600 /root/.kaggle/kaggle.json\n\n# !pwd\n\n# !kaggle datasets download -d neelshah2022/indian-news-dataset-with-ministry-labels","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"EkJuWSsfcUdN","outputId":"508f0f7a-aac8-4c8d-c1e6-d4ff676b01af","execution":{"iopub.status.busy":"2023-12-26T10:40:11.977542Z","iopub.execute_input":"2023-12-26T10:40:11.977890Z","iopub.status.idle":"2023-12-26T10:40:11.983136Z","shell.execute_reply.started":"2023-12-26T10:40:11.977862Z","shell.execute_reply":"2023-12-26T10:40:11.982207Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!unzip /content/indian-news-dataset-with-ministry-labels.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q1TSVb2vfbHG","outputId":"be9a6272-70b5-41d7-cfdf-305be2fd406d","execution":{"iopub.status.busy":"2023-12-26T10:40:11.985051Z","iopub.execute_input":"2023-12-26T10:40:11.985830Z","iopub.status.idle":"2023-12-26T10:40:12.919304Z","shell.execute_reply.started":"2023-12-26T10:40:11.985798Z","shell.execute_reply":"2023-12-26T10:40:12.918387Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"unzip:  cannot find or open /content/indian-news-dataset-with-ministry-labels.zip, /content/indian-news-dataset-with-ministry-labels.zip.zip or /content/indian-news-dataset-with-ministry-labels.zip.ZIP.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h2>\n<h2>TODO</h2>\n<ul>\n<li>Padding length is to be set, According to the result wanted, Currently padding length is seted to the `550`.</li>    \n</ul>\n</h2>","metadata":{"id":"Q1SM9N-xcRsg"}},{"cell_type":"markdown","source":"<h1>Process 1: Importing the Libraries</h1>","metadata":{"id":"PtGYrLRScRsh"}},{"cell_type":"code","source":"# For basic dataframe and mathematical operations\nimport numpy as np\nimport pandas as pd\n\n# For Deep Learning Model\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow import keras\nimport os\n\n# For natural language processing\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\n# For utility\nimport re\n# import lgging\nimport time\nimport pickle\nimport itertools\n","metadata":{"id":"fpvil8fCcRsi","execution":{"iopub.status.busy":"2023-12-26T10:40:12.920546Z","iopub.execute_input":"2023-12-26T10:40:12.920816Z","iopub.status.idle":"2023-12-26T10:40:25.340725Z","shell.execute_reply.started":"2023-12-26T10:40:12.920793Z","shell.execute_reply":"2023-12-26T10:40:25.339935Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h2>Processs 2: Code for configuring multiple GPUs</h2>","metadata":{"id":"ztdFbu5ucRsk"}},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-3BQY1JcRsl","outputId":"1b5138b7-d184-46db-cbb9-8f2313c3802c","execution":{"iopub.status.busy":"2023-12-26T10:40:25.342528Z","iopub.execute_input":"2023-12-26T10:40:25.343042Z","iopub.status.idle":"2023-12-26T10:40:27.915011Z","shell.execute_reply.started":"2023-12-26T10:40:25.343015Z","shell.execute_reply":"2023-12-26T10:40:27.914072Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 13063117092820859852\nxla_global_id: -1\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 16120545280\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 8505790588069968824\nphysical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\nxla_global_id: 416903419\n]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h1>Process 3: Making press release dataset ready for giving it as input to classification model</h1>","metadata":{"id":"7Q-xUmoicRsl"}},{"cell_type":"markdown","source":"<h2>Managining new 61th i.e. no ministry labeled datatset for classification model</h2>","metadata":{"id":"GMnXBslQcRsm"}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/indian-news-dataset-with-ministry-labels/combined_dataset.csv\", encoding='unicode_escape')","metadata":{"id":"MZIm3R53cRsm","execution":{"iopub.status.busy":"2023-12-26T10:40:27.917078Z","iopub.execute_input":"2023-12-26T10:40:27.918104Z","iopub.status.idle":"2023-12-26T10:40:28.734683Z","shell.execute_reply.started":"2023-12-26T10:40:27.918076Z","shell.execute_reply":"2023-12-26T10:40:28.733702Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"<h2>Managing press release dataset</h2>","metadata":{"id":"Uru78_ttcRsn"}},{"cell_type":"markdown","source":"<h2>List of the ministry and it's specific index number</h2>\n<ul>\n<li> 0 Ministry of Railways </li>\n<li> 1 Ministry of Rural Development </li>\n<li> 2 Ministry of Steel </li>\n<li> 3 Ministry of Science & Technology </li>\n<li> 4 Ministry of Information & Broadcasting </li>\n<li> 5 Ministry of Food Processing Industries </li>\n<li> 6 Ministry of Health and Family Welfare </li>\n<li> 7 Ministry of Human Resource Development </li>\n<li> 8 Ministry of Agriculture </li>\n<li> 9 Ministry of Environment and Forests </li>\n<li> 10 Ministry of Chemicals and Fertilizers </li>\n<li> 11 Ministry of Water Resources </li>\n<li> 12 Ministry of Defence </li>\n<li> 13 Ministry of Petroleum & Natural Gas </li>\n<li> 14 President's Secretariat </li>\n<li> 15 Ministry of Micro,Small & Medium Enterprises </li>\n<li> 16 Ministry of Mines </li>\n<li> 17 Ministry of Tourism </li>\n<li> 18 Ministry of Housing & Urban Affairs </li>\n<li> 19 Ministry of Coal </li>\n<li> 20 Prime Minister's Office </li>\n<li> 21 Ministry of Textiles </li>\n<li> 22 Ministry of Commerce & Industry </li>\n<li> 23 Ministry of External Affairs </li>\n<li> 24 Ministry of Social Justice & Empowerment </li>\n<li> 25 Ministry of Power </li>\n<li> 26 Ministry of Consumer Affairs, Food & Public Distribution </li>\n<li> 27 Ministry of Heavy Industries & Public Enterprises </li>\n<li> 28 Ministry of Communications </li>\n<li> 29 Ministry of Shipping </li>\n<li> 30 Ministry of Finance </li>\n<li> 31 Ministry of Tribal Affairs </li>\n<li> 32 Ministry of Statistics & Programme Implementation </li>\n<li> 33 Ministry of Labour & Employment </li>\n<li> 34 Ministry of Law & Justice </li>\n<li> 35 Vice President's Secretariat </li>\n<li> 36 Ministry of Civil Aviation </li>\n<li> 37 Ministry for Development of North-East Region </li>\n<li> 38 UPSC </li>\n<li> 39 Ministry of Agro & Rural Industries </li>\n<li> 40 Ministry of Home Affairs </li>\n<li> 41 Ministry of Youth Affairs and Sports </li>\n<li> 42 Special Service and Features </li>\n<li> 43 Ministry of New and Renewable Energy </li>\n<li> 44 Ministry of Parliamentary Affairs </li>\n<li> 45 Planning Commission </li>\n<li> 46 Ministry of Personnel, Public Grievances & Pensions </li>\n<li> 47 Election Commission </li>\n<li> 48 Department of Space </li>\n<li> 49 Ministry of Disinvestment </li>\n<li> 50 Department of Ocean Development </li>\n<li> 51 Ministry of Overseas Indian Affairs </li>\n<li> 52 Ministry of Housing and Urban Poverty Alleviation </li>\n<li> 53 Ministry of Culture </li>\n<li> 54 Ministry of Company Affairs </li>\n<li> 55 Ministry of Panchayati Raj </li>\n<li> 56 Cabinet Committee on Economic Affairs (CCEA) </li>\n<li> 57 Cabinet </li>\n<li> 58 Department of Atomic Energy </li>\n<li> 59 Cabinet Committee Decisions </li>\n<li>60 No Ministry</li>\n</ul>","metadata":{"id":"KxcpZ1JgcRsn"}},{"cell_type":"markdown","source":"<b>Mapping the ministry to the it's index number starting from the 1 and `0` is made reserved for the `Not Ministry`, If any news doesn't belongs to any ministry of our current ministry dataset, So total labels are `59+1(no ministry)`</b>","metadata":{"id":"GeNffOEicRsn"}},{"cell_type":"markdown","source":"<h3>Making the cocatination of the pr_title and pr_content in the new field named content</h3>","metadata":{"id":"jyA87QdlcRsn"}},{"cell_type":"code","source":"tmp =  df.labels.isnull()\nfor idx, val in enumerate(tmp):\n    if val == True:\n        print(df['news_num'][idx], df['labels'][idx], df['content'][idx])\n        print('\\n')","metadata":{"id":"XxT1isnicRsn","execution":{"iopub.status.busy":"2023-12-26T10:40:28.735874Z","iopub.execute_input":"2023-12-26T10:40:28.736186Z","iopub.status.idle":"2023-12-26T10:40:28.757226Z","shell.execute_reply.started":"2023-12-26T10:40:28.736161Z","shell.execute_reply":"2023-12-26T10:40:28.756356Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for i in range(len(df)):\n    if pd.isnull(df.loc[i, 'title']):\n        df.loc[i, 'content'] = str(df.loc[i, 'content'])[:550]\n    elif pd.isnull(df.loc[i, 'content']):\n        df.loc[i, 'content'] = str(df.loc[i, 'title'])[:550]\n    else:\n        df.loc[i, 'content'] = (str(df.loc[i, 'title']) + \" \" + str(df.loc[i, 'content']))[:550]\ndf.drop(columns=['news_num', 'title'], inplace=True)","metadata":{"id":"IAM33dJScRsn","execution":{"iopub.status.busy":"2023-12-26T10:40:28.758360Z","iopub.execute_input":"2023-12-26T10:40:28.758974Z","iopub.status.idle":"2023-12-26T10:40:43.598881Z","shell.execute_reply.started":"2023-12-26T10:40:28.758950Z","shell.execute_reply":"2023-12-26T10:40:43.597871Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"qiaAvs0McRso","outputId":"187d8395-99e5-4b92-ec9a-4d4a3ec5cc99","execution":{"iopub.status.busy":"2023-12-26T10:40:43.600317Z","iopub.execute_input":"2023-12-26T10:40:43.600764Z","iopub.status.idle":"2023-12-26T10:40:43.614961Z","shell.execute_reply.started":"2023-12-26T10:40:43.600731Z","shell.execute_reply":"2023-12-26T10:40:43.613853Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  labels                                            content\n0      0  Trainer aircraft crashes in Odisha, 2 killed A...\n1     17  Uttarkhand unlock 1.0: Hotel bookings for mini...\n2     12  J-K: Four Hizbul militants killed in Shopian e...\n3  54,33  Mumbai offices to reopen today, with curbs Pri...\n4     12  PDP, NC, PC call for release of all J&K leader...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>labels</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Trainer aircraft crashes in Odisha, 2 killed A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>Uttarkhand unlock 1.0: Hotel bookings for mini...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>J-K: Four Hizbul militants killed in Shopian e...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54,33</td>\n      <td>Mumbai offices to reopen today, with curbs Pri...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>PDP, NC, PC call for release of all J&amp;K leader...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<h2>Concatinating press release and 0 label dataset</h2>","metadata":{"id":"cJRLz5PEcRso"}},{"cell_type":"code","source":"# df = pd.concat([df, df4, df5, df6], ignore_index=True)","metadata":{"id":"px-WZR4QcRso","execution":{"iopub.status.busy":"2023-12-26T10:40:43.619612Z","iopub.execute_input":"2023-12-26T10:40:43.619857Z","iopub.status.idle":"2023-12-26T10:40:43.624342Z","shell.execute_reply.started":"2023-12-26T10:40:43.619836Z","shell.execute_reply":"2023-12-26T10:40:43.623395Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# df.head()","metadata":{"id":"zeJ6FAPAcRso","execution":{"iopub.status.busy":"2023-12-26T10:40:43.626547Z","iopub.execute_input":"2023-12-26T10:40:43.626824Z","iopub.status.idle":"2023-12-26T10:40:43.632989Z","shell.execute_reply.started":"2023-12-26T10:40:43.626801Z","shell.execute_reply":"2023-12-26T10:40:43.632045Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# df.describe(include='object')","metadata":{"id":"n6kIfdyfcRso","execution":{"iopub.status.busy":"2023-12-26T10:40:43.634205Z","iopub.execute_input":"2023-12-26T10:40:43.634910Z","iopub.status.idle":"2023-12-26T10:40:43.641762Z","shell.execute_reply.started":"2023-12-26T10:40:43.634879Z","shell.execute_reply":"2023-12-26T10:40:43.640873Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<h3>Shuffling Dataframe</h3>","metadata":{"id":"YwIakflAcRso"}},{"cell_type":"code","source":"# df = df.sample(frac = 1)","metadata":{"id":"1XK89SWWcRso","execution":{"iopub.status.busy":"2023-12-26T10:40:43.642996Z","iopub.execute_input":"2023-12-26T10:40:43.643637Z","iopub.status.idle":"2023-12-26T10:40:43.650263Z","shell.execute_reply.started":"2023-12-26T10:40:43.643606Z","shell.execute_reply":"2023-12-26T10:40:43.649441Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"<h2>Preprocessing and Lemmatizing the text, So that makning the text to the it's base form. So that there would be no repetation allotment of the same keyword in the different state</h2>","metadata":{"id":"qcXjWnxpcRsp"}},{"cell_type":"code","source":"nltk.download('stopwords')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhhOqlfocRsp","outputId":"fb24e811-60fd-4ad8-bae4-55d7e201554a","execution":{"iopub.status.busy":"2023-12-26T10:40:43.651357Z","iopub.execute_input":"2023-12-26T10:40:43.651666Z","iopub.status.idle":"2023-12-26T10:40:43.732419Z","shell.execute_reply.started":"2023-12-26T10:40:43.651644Z","shell.execute_reply":"2023-12-26T10:40:43.731443Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = stopwords.words(\"english\")\nstemmer = SnowballStemmer(\"english\")","metadata":{"id":"7IZwZbwBcRsp","execution":{"iopub.status.busy":"2023-12-26T10:40:43.733613Z","iopub.execute_input":"2023-12-26T10:40:43.733938Z","iopub.status.idle":"2023-12-26T10:40:43.740746Z","shell.execute_reply.started":"2023-12-26T10:40:43.733900Z","shell.execute_reply":"2023-12-26T10:40:43.739773Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def preprocess(text, stem=False):\n    # Removing link, user, special characters\n    test = re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', str(text).lower()).strip()\n    tokens = []\n    for token in text.split():\n        if token not in stop_words:\n            if stem:\n                tokens.append(stemmer.stem(token))\n            else:\n                tokens.append(token)\n    return \" \".join(tokens)","metadata":{"id":"STFJuwutcRsp","execution":{"iopub.status.busy":"2023-12-26T10:40:43.742158Z","iopub.execute_input":"2023-12-26T10:40:43.742525Z","iopub.status.idle":"2023-12-26T10:40:43.749352Z","shell.execute_reply.started":"2023-12-26T10:40:43.742495Z","shell.execute_reply":"2023-12-26T10:40:43.748383Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for i in range(len(df)):\n    df.loc[i, 'content'] = preprocess(df.loc[i, 'content'], True)","metadata":{"id":"4E04ITimcRsp","execution":{"iopub.status.busy":"2023-12-26T10:40:43.750774Z","iopub.execute_input":"2023-12-26T10:40:43.751150Z","iopub.status.idle":"2023-12-26T10:41:34.130475Z","shell.execute_reply.started":"2023-12-26T10:40:43.751058Z","shell.execute_reply":"2023-12-26T10:41:34.129475Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<h1>Doing OneHot encoding of the labels</h2>","metadata":{"id":"Udn3jnJjcRsp"}},{"cell_type":"code","source":"df['labels'][458]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DfDGFcLacRsp","outputId":"af1eb572-17d9-43ae-8a46-4deae5331c36","execution":{"iopub.status.busy":"2023-12-26T10:41:34.131731Z","iopub.execute_input":"2023-12-26T10:41:34.132036Z","iopub.status.idle":"2023-12-26T10:41:34.137933Z","shell.execute_reply.started":"2023-12-26T10:41:34.132012Z","shell.execute_reply":"2023-12-26T10:41:34.137055Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'6,7'"},"metadata":{}}]},{"cell_type":"markdown","source":"<h2>Making the custom one hot labeling function as per the requriement</h2>","metadata":{"id":"gBPn0nEccRsq"}},{"cell_type":"code","source":"# def make_one_hot_encoding(num_ministries, tmp_label_list):\n#     outer_list = []\n\n#     for i in range(len(tmp_label_list)):\n#         inner_list = [0]*num_ministries\n#         for j in tmp_label_list[i]:\n#             inner_list[j] = 1\n#         outer_list.append(inner_list)\n#     return outer_list","metadata":{"id":"TuiVwj79cRsq","execution":{"iopub.status.busy":"2023-12-26T10:41:34.138997Z","iopub.execute_input":"2023-12-26T10:41:34.139256Z","iopub.status.idle":"2023-12-26T10:41:34.150525Z","shell.execute_reply.started":"2023-12-26T10:41:34.139226Z","shell.execute_reply":"2023-12-26T10:41:34.149694Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# num_classes = 61\n\n# # onehot_labels = make_one_hot_encoding(61, tmp_label_list)\n# onehot_labels = []\n# for label_list in tmp_label_list:\n#     categorical = tf.keras.utils.to_categorical(label_list, num_classes=num_classes)\n#     if len(categorical) >1:\n#         i=0\n#         for list_ in categorical:\n#             if i==0:\n#                 ans = np.asarray(list_.tolist())\n#             else:\n#                 ans = ans + np.asarray(list_.tolist())\n#             i+=1\n#         onehot_labels.append(ans)\n#     else:\n#         onehot_labels.append(np.asarray(categorical.flatten().tolist()))\n\n# onehot_labels = np.asarray(onehot_labels)","metadata":{"id":"AAZ1GPwycRsq","execution":{"iopub.status.busy":"2023-12-26T10:41:34.151588Z","iopub.execute_input":"2023-12-26T10:41:34.151876Z","iopub.status.idle":"2023-12-26T10:41:34.159200Z","shell.execute_reply.started":"2023-12-26T10:41:34.151854Z","shell.execute_reply":"2023-12-26T10:41:34.158465Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def convert_to_multi_one_hot(df, label_col, num_classes):\n\n    # Split labels by comma\n    labels = df[label_col].apply(lambda x: x.split(\",\")).values\n    # Initialize one-hot encoding array\n    one_hot = np.zeros((len(labels), num_classes))\n    for i, label_vals in enumerate(labels):\n        # Clean individual values\n        cleaned = []\n        for l in label_vals:\n            l = l.strip().rstrip(\".\") # Strip whitespace and periods\n            try:\n                index = int(l) # Attempt integer conversion\n                cleaned.append(index)\n            except ValueError:\n                print(f\"Skipping invalid label value {l}\")\n                pass # Skip invalid values\n\n            # Set encoding from cleaned values\n            indices = [int(l) for l in cleaned]\n            one_hot[i, indices] = 1\n    return one_hot\n\nonehot_labels = convert_to_multi_one_hot(df, \"labels\", 61)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dnmUPMzWcRsq","outputId":"75e691c5-ece3-4cdf-e15c-2efa6818aef8","execution":{"iopub.status.busy":"2023-12-26T10:41:34.160453Z","iopub.execute_input":"2023-12-26T10:41:34.160731Z","iopub.status.idle":"2023-12-26T10:41:34.382155Z","shell.execute_reply.started":"2023-12-26T10:41:34.160709Z","shell.execute_reply":"2023-12-26T10:41:34.381248Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Skipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value \nSkipping invalid label value 41`\n","output_type":"stream"}]},{"cell_type":"code","source":"print(onehot_labels[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yS585q12cRsq","outputId":"5fdbe99c-53da-4c89-dd9c-c7fdfdd8e26d","execution":{"iopub.status.busy":"2023-12-26T10:41:34.383473Z","iopub.execute_input":"2023-12-26T10:41:34.384270Z","iopub.status.idle":"2023-12-26T10:41:34.390184Z","shell.execute_reply.started":"2023-12-26T10:41:34.384235Z","shell.execute_reply":"2023-12-26T10:41:34.389206Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","output_type":"stream"}]},{"cell_type":"code","source":"onehot_labels[3]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3FnR31HcRsq","outputId":"f7d506fc-39d8-4510-9d03-437028a03feb","execution":{"iopub.status.busy":"2023-12-26T10:41:34.391367Z","iopub.execute_input":"2023-12-26T10:41:34.391659Z","iopub.status.idle":"2023-12-26T10:41:34.402624Z","shell.execute_reply.started":"2023-12-26T10:41:34.391636Z","shell.execute_reply":"2023-12-26T10:41:34.401724Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"markdown","source":"<h2>Tokenising Text</h2>","metadata":{"id":"eMnigG9PcRsq"}},{"cell_type":"code","source":"tokenizer = keras.preprocessing.text.Tokenizer(oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(df.content)\n\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Total Words\", vocab_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYK7hSgBcRsr","outputId":"d2e0f0d8-29af-417a-c266-2960be324871","execution":{"iopub.status.busy":"2023-12-26T10:41:34.403667Z","iopub.execute_input":"2023-12-26T10:41:34.403931Z","iopub.status.idle":"2023-12-26T10:41:36.867815Z","shell.execute_reply.started":"2023-12-26T10:41:34.403908Z","shell.execute_reply":"2023-12-26T10:41:36.866765Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Total Words 69087\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<b>For saving the tokenizer</b>","metadata":{"id":"gLje7W3UcRsr"}},{"cell_type":"code","source":"# ALREADY COMMENTED FROM BEGINING, THIS PART IS NOT COMMENTED DURING THE DATASET CHANGE\n\n# import json\n\n# # Serialize the tokenizer's configuration to JSON\n# tokenizer_config = tokenizer.to_json()\n\n# # Save the tokenizer configuration to a file\n# with open('tokenizer_config.json', 'w', encoding='utf-8') as json_file:\n#     json.dump(tokenizer_config, json_file, ensure_ascii=False, indent=4)\n\n# # Optionally, save the tokenizer weights to a separate file (e.g., for the embeddings layer)\n# # tokenizer.word_index contains the vocabulary and word-to-index mapping\n# with open('tokenizer_weights.json', 'w', encoding='utf-8') as json_file:\n#     json.dump(tokenizer.word_index, json_file, ensure_ascii=False, indent=4)","metadata":{"id":"GJWtBvOycRsr","execution":{"iopub.status.busy":"2023-12-26T10:41:36.873478Z","iopub.execute_input":"2023-12-26T10:41:36.873779Z","iopub.status.idle":"2023-12-26T10:41:36.878074Z","shell.execute_reply.started":"2023-12-26T10:41:36.873753Z","shell.execute_reply":"2023-12-26T10:41:36.877210Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"<b>For converting the text to the sequence of tokens</b>","metadata":{"id":"NUoDfgI_cRsu"}},{"cell_type":"code","source":"tokenized_train_text = tokenizer.texts_to_sequences(df.content)\n# tokenized_train_text = same for test","metadata":{"id":"a5kZ-gFecRsv","execution":{"iopub.status.busy":"2023-12-26T10:41:36.879181Z","iopub.execute_input":"2023-12-26T10:41:36.879491Z","iopub.status.idle":"2023-12-26T10:41:38.841432Z","shell.execute_reply.started":"2023-12-26T10:41:36.879468Z","shell.execute_reply":"2023-12-26T10:41:38.840651Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"<h2><b>Currently setting the the padding length to be equal to the maxlength of the content, But in the applciacation one length have to be made fixed for this pupose, if cotent is more than that then the content will be croped</b></h2>\n\n<b>OR</b>\n\n<h2>\n<b>\n    One have to change the input layer dimension of the model, during the inference time\n</b>\n<h2>\n<b>It is remaining to make the test dataset, And by help of the padding make sure in it that the input size is same as that of the input layer, otherwise it will give an error</b>","metadata":{"id":"UZB0HS8BcRsw"}},{"cell_type":"markdown","source":"<b>Finding the max length of the content from the dataset, To make it the height text or sequence length for all of one, So that the input would have the same dimensions by help of the padding</b>","metadata":{"id":"5W74QUVicRsw"}},{"cell_type":"code","source":"# max_sequence_len_tmp = max([len(x) for x in df.content])\nmax_sequence_len_tmp = 550 # As per the EDA report of the dataset by Neel Shah","metadata":{"id":"9POaN0fScRsx","execution":{"iopub.status.busy":"2023-12-26T10:41:38.842465Z","iopub.execute_input":"2023-12-26T10:41:38.842754Z","iopub.status.idle":"2023-12-26T10:41:38.847899Z","shell.execute_reply.started":"2023-12-26T10:41:38.842730Z","shell.execute_reply":"2023-12-26T10:41:38.846293Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"<h2>TODO: Also check for the pre</h2>","metadata":{"id":"Q-GyJCsecRsx"}},{"cell_type":"code","source":"x_train = keras.preprocessing.sequence.pad_sequences(tokenized_train_text, maxlen=max_sequence_len_tmp, truncating='post',)\n# x_test = same for test as of train","metadata":{"id":"G0FN98ZrcRsx","execution":{"iopub.status.busy":"2023-12-26T10:41:38.849039Z","iopub.execute_input":"2023-12-26T10:41:38.849320Z","iopub.status.idle":"2023-12-26T10:41:39.166445Z","shell.execute_reply.started":"2023-12-26T10:41:38.849297Z","shell.execute_reply":"2023-12-26T10:41:39.165449Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"x_train[2]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxu_igbZcRsx","outputId":"56b90a4a-50fd-4fc6-ade8-4e45e5312725","execution":{"iopub.status.busy":"2023-12-26T10:41:39.167546Z","iopub.execute_input":"2023-12-26T10:41:39.167817Z","iopub.status.idle":"2023-12-26T10:41:39.175766Z","shell.execute_reply.started":"2023-12-26T10:41:39.167795Z","shell.execute_reply":"2023-12-26T10:41:39.174891Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,   151,    96,    97,  3169,   737,    78,  3200,  1030,\n         446,    53,   254, 37311,   737,    78,    15,   190,   607,\n         280,  1030,   350,    68,  3200,    42,  1122,   101,   224,\n        1030,  3200,    53,   254,   948,   666,   737,    78,    15,\n        3973,    11,   179,    41,   137,     2,    30,   186,   737,\n          78,   171,  1314,  3169,  3503,  1754,     2,  5841,    70,\n          13,   123,   737,    78,  1030, 22555,   169,  3200,    27,\n         288], dtype=int32)"},"metadata":{}}]},{"cell_type":"markdown","source":"next, to do label encdcoder, whicg encodes the value betn 0 and 1, but","metadata":{"id":"uJ2K73VGcRsx"}},{"cell_type":"code","source":"# Embedding dimensions to be changed as per the in which highest accuracy is got\nimport tensorflow as tf\nfrom keras.metrics import top_k_categorical_accuracy\nfrom keras.layers import Conv1D, GlobalMaxPooling1D, Bidirectional, LSTM, Dense\n# Create a MirroredStrategy to use all available GPUs\nstrategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n\n    model = tf.keras.Sequential([\n        tf.keras.layers.Embedding(vocab_size, 300, input_length=max_sequence_len_tmp),\n        Conv1D(filters=512, kernel_size=3, activation='relu'),\n        Conv1D(filters=256, kernel_size=3, activation='relu'),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n        # GlobalMaxPooling1D(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(61, activation='softmax')\n    ])\n\n    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.0010), metrics=['accuracy', top_k_categorical_accuracy])\n    model.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F0FCV0u1cRsx","outputId":"0d783fc6-1343-4a96-d3bf-ffaed0becfa2","execution":{"iopub.status.busy":"2023-12-26T10:41:39.177009Z","iopub.execute_input":"2023-12-26T10:41:39.177336Z","iopub.status.idle":"2023-12-26T10:41:40.733898Z","shell.execute_reply.started":"2023-12-26T10:41:39.177307Z","shell.execute_reply":"2023-12-26T10:41:40.733004Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 550, 300)          20726100  \n                                                                 \n conv1d (Conv1D)             (None, 548, 512)          461312    \n                                                                 \n conv1d_1 (Conv1D)           (None, 546, 256)          393472    \n                                                                 \n bidirectional (Bidirection  (None, 546, 128)          164352    \n al)                                                             \n                                                                 \n bidirectional_1 (Bidirecti  (None, 128)               98816     \n onal)                                                           \n                                                                 \n dense (Dense)               (None, 128)               16512     \n                                                                 \n dense_1 (Dense)             (None, 61)                7869      \n                                                                 \n=================================================================\nTotal params: 21868433 (83.42 MB)\nTrainable params: 21868433 (83.42 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# x_train = tf.convert_to_tensor(x_train)\n# type(x_train)","metadata":{"id":"gwEY6oTpcRsy","execution":{"iopub.status.busy":"2023-12-26T10:41:40.735054Z","iopub.execute_input":"2023-12-26T10:41:40.735328Z","iopub.status.idle":"2023-12-26T10:41:40.739276Z","shell.execute_reply.started":"2023-12-26T10:41:40.735305Z","shell.execute_reply":"2023-12-26T10:41:40.738335Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# onehot_labels = tf.convert_to_tensor(onehot_labels, dtype=tf.float32)","metadata":{"id":"C_EYi_jpcRsy","execution":{"iopub.status.busy":"2023-12-26T10:41:40.740356Z","iopub.execute_input":"2023-12-26T10:41:40.740668Z","iopub.status.idle":"2023-12-26T10:41:40.749565Z","shell.execute_reply.started":"2023-12-26T10:41:40.740645Z","shell.execute_reply":"2023-12-26T10:41:40.748638Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Define a callback to save model checkpoints during training\ncheckpoint_callback = ModelCheckpoint(\n    filepath='/kaggle/working/model_checkpoint.h5',  # Path to save the checkpoint file\n    monitor='val_accuracy',  # Metric to monitor for saving (e.g., validation accuracy)\n    verbose=1,  # Verbosity level (0 or 1)\n    save_best_only=True,  # Save only the best model (based on the monitored metric)\n    mode='max'  # Mode of monitoring ('max' or 'min' for accuracy)\n)","metadata":{"id":"CkIJhCBkcRsy","execution":{"iopub.status.busy":"2023-12-26T10:41:40.750622Z","iopub.execute_input":"2023-12-26T10:41:40.750875Z","iopub.status.idle":"2023-12-26T10:41:40.759291Z","shell.execute_reply.started":"2023-12-26T10:41:40.750854Z","shell.execute_reply":"2023-12-26T10:41:40.758370Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100\n\nimport tensorflow as tf\n\n# Create a MirroredStrategy to use all available GPUs\nwith strategy.scope():\n    callbacks = [ tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n                  tf.keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]\n    history = model.fit(x_train, onehot_labels, validation_split=0.2, batch_size=1024, epochs=num_epochs, verbose=1, callbacks=[callbacks, checkpoint_callback])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cP5w4RApcRsy","outputId":"2663127d-cd98-447a-d40d-dd6d4f5147ad","execution":{"iopub.status.busy":"2023-12-26T10:41:40.760588Z","iopub.execute_input":"2023-12-26T10:41:40.760824Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\n29/29 [==============================] - ETA: 0s - loss: 3.0386 - accuracy: 0.3432 - top_k_categorical_accuracy: 0.6084\nEpoch 1: val_accuracy improved from -inf to 0.53238, saving model to /kaggle/working/model_checkpoint.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"29/29 [==============================] - 55s 1s/step - loss: 3.0386 - accuracy: 0.3432 - top_k_categorical_accuracy: 0.6084 - val_loss: 2.2919 - val_accuracy: 0.5324 - val_top_k_categorical_accuracy: 0.7340 - lr: 0.0010\nEpoch 2/100\n29/29 [==============================] - ETA: 0s - loss: 2.6030 - accuracy: 0.3584 - top_k_categorical_accuracy: 0.7006\nEpoch 2: val_accuracy did not improve from 0.53238\n29/29 [==============================] - 27s 944ms/step - loss: 2.6030 - accuracy: 0.3584 - top_k_categorical_accuracy: 0.7006 - val_loss: 2.1169 - val_accuracy: 0.5303 - val_top_k_categorical_accuracy: 0.7587 - lr: 0.0010\nEpoch 3/100\n29/29 [==============================] - ETA: 0s - loss: 2.3564 - accuracy: 0.4277 - top_k_categorical_accuracy: 0.7242\nEpoch 3: val_accuracy did not improve from 0.53238\n29/29 [==============================] - 27s 945ms/step - loss: 2.3564 - accuracy: 0.4277 - top_k_categorical_accuracy: 0.7242 - val_loss: 2.0041 - val_accuracy: 0.5028 - val_top_k_categorical_accuracy: 0.8222 - lr: 0.0010\nEpoch 4/100\n29/29 [==============================] - ETA: 0s - loss: 2.1248 - accuracy: 0.4858 - top_k_categorical_accuracy: 0.7590\nEpoch 4: val_accuracy did not improve from 0.53238\n29/29 [==============================] - 27s 944ms/step - loss: 2.1248 - accuracy: 0.4858 - top_k_categorical_accuracy: 0.7590 - val_loss: 2.0052 - val_accuracy: 0.5028 - val_top_k_categorical_accuracy: 0.8175 - lr: 0.0010\nEpoch 5/100\n29/29 [==============================] - ETA: 0s - loss: 1.9413 - accuracy: 0.5236 - top_k_categorical_accuracy: 0.7840\nEpoch 5: val_accuracy improved from 0.53238 to 0.54070, saving model to /kaggle/working/model_checkpoint.h5\n29/29 [==============================] - 28s 971ms/step - loss: 1.9413 - accuracy: 0.5236 - top_k_categorical_accuracy: 0.7840 - val_loss: 1.9503 - val_accuracy: 0.5407 - val_top_k_categorical_accuracy: 0.8092 - lr: 0.0010\nEpoch 6/100\n29/29 [==============================] - ETA: 0s - loss: 1.7686 - accuracy: 0.5702 - top_k_categorical_accuracy: 0.8031\nEpoch 6: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 944ms/step - loss: 1.7686 - accuracy: 0.5702 - top_k_categorical_accuracy: 0.8031 - val_loss: 2.0172 - val_accuracy: 0.5343 - val_top_k_categorical_accuracy: 0.7955 - lr: 0.0010\nEpoch 7/100\n29/29 [==============================] - ETA: 0s - loss: 1.6398 - accuracy: 0.6017 - top_k_categorical_accuracy: 0.8235\nEpoch 7: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 1.6398 - accuracy: 0.6017 - top_k_categorical_accuracy: 0.8235 - val_loss: 2.2175 - val_accuracy: 0.4865 - val_top_k_categorical_accuracy: 0.7712 - lr: 0.0010\nEpoch 8/100\n29/29 [==============================] - ETA: 0s - loss: 1.5163 - accuracy: 0.6333 - top_k_categorical_accuracy: 0.8395\nEpoch 8: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 944ms/step - loss: 1.5163 - accuracy: 0.6333 - top_k_categorical_accuracy: 0.8395 - val_loss: 2.3192 - val_accuracy: 0.4905 - val_top_k_categorical_accuracy: 0.7656 - lr: 0.0010\nEpoch 9/100\n29/29 [==============================] - ETA: 0s - loss: 1.4154 - accuracy: 0.6576 - top_k_categorical_accuracy: 0.8539\nEpoch 9: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 1.4154 - accuracy: 0.6576 - top_k_categorical_accuracy: 0.8539 - val_loss: 2.4608 - val_accuracy: 0.4832 - val_top_k_categorical_accuracy: 0.7433 - lr: 0.0010\nEpoch 10/100\n29/29 [==============================] - ETA: 0s - loss: 1.3097 - accuracy: 0.6841 - top_k_categorical_accuracy: 0.8726\nEpoch 10: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 944ms/step - loss: 1.3097 - accuracy: 0.6841 - top_k_categorical_accuracy: 0.8726 - val_loss: 2.6518 - val_accuracy: 0.4517 - val_top_k_categorical_accuracy: 0.7179 - lr: 0.0010\nEpoch 11/100\n29/29 [==============================] - ETA: 0s - loss: 1.1692 - accuracy: 0.7216 - top_k_categorical_accuracy: 0.8950\nEpoch 11: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 944ms/step - loss: 1.1692 - accuracy: 0.7216 - top_k_categorical_accuracy: 0.8950 - val_loss: 2.7281 - val_accuracy: 0.4625 - val_top_k_categorical_accuracy: 0.7136 - lr: 1.0000e-04\nEpoch 12/100\n29/29 [==============================] - ETA: 0s - loss: 1.1100 - accuracy: 0.7371 - top_k_categorical_accuracy: 0.9031\nEpoch 12: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 944ms/step - loss: 1.1100 - accuracy: 0.7371 - top_k_categorical_accuracy: 0.9031 - val_loss: 2.8017 - val_accuracy: 0.4632 - val_top_k_categorical_accuracy: 0.7124 - lr: 1.0000e-04\nEpoch 13/100\n29/29 [==============================] - ETA: 0s - loss: 1.0729 - accuracy: 0.7475 - top_k_categorical_accuracy: 0.9070\nEpoch 13: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 1.0729 - accuracy: 0.7475 - top_k_categorical_accuracy: 0.9070 - val_loss: 2.8579 - val_accuracy: 0.4590 - val_top_k_categorical_accuracy: 0.7099 - lr: 1.0000e-04\nEpoch 14/100\n29/29 [==============================] - ETA: 0s - loss: 1.0407 - accuracy: 0.7587 - top_k_categorical_accuracy: 0.9121\nEpoch 14: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 1.0407 - accuracy: 0.7587 - top_k_categorical_accuracy: 0.9121 - val_loss: 2.9112 - val_accuracy: 0.4589 - val_top_k_categorical_accuracy: 0.7091 - lr: 1.0000e-04\nEpoch 15/100\n29/29 [==============================] - ETA: 0s - loss: 1.0149 - accuracy: 0.7670 - top_k_categorical_accuracy: 0.9153\nEpoch 15: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 1.0149 - accuracy: 0.7670 - top_k_categorical_accuracy: 0.9153 - val_loss: 2.9722 - val_accuracy: 0.4499 - val_top_k_categorical_accuracy: 0.7000 - lr: 1.0000e-04\nEpoch 16/100\n29/29 [==============================] - ETA: 0s - loss: 0.9925 - accuracy: 0.7752 - top_k_categorical_accuracy: 0.9173\nEpoch 16: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9925 - accuracy: 0.7752 - top_k_categorical_accuracy: 0.9173 - val_loss: 2.9731 - val_accuracy: 0.4543 - val_top_k_categorical_accuracy: 0.7028 - lr: 1.0000e-05\nEpoch 17/100\n29/29 [==============================] - ETA: 0s - loss: 0.9894 - accuracy: 0.7762 - top_k_categorical_accuracy: 0.9180\nEpoch 17: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9894 - accuracy: 0.7762 - top_k_categorical_accuracy: 0.9180 - val_loss: 2.9811 - val_accuracy: 0.4544 - val_top_k_categorical_accuracy: 0.7035 - lr: 1.0000e-05\nEpoch 18/100\n29/29 [==============================] - ETA: 0s - loss: 0.9865 - accuracy: 0.7770 - top_k_categorical_accuracy: 0.9183\nEpoch 18: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 939ms/step - loss: 0.9865 - accuracy: 0.7770 - top_k_categorical_accuracy: 0.9183 - val_loss: 2.9888 - val_accuracy: 0.4542 - val_top_k_categorical_accuracy: 0.7021 - lr: 1.0000e-05\nEpoch 19/100\n29/29 [==============================] - ETA: 0s - loss: 0.9840 - accuracy: 0.7787 - top_k_categorical_accuracy: 0.9186\nEpoch 19: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 942ms/step - loss: 0.9840 - accuracy: 0.7787 - top_k_categorical_accuracy: 0.9186 - val_loss: 2.9939 - val_accuracy: 0.4543 - val_top_k_categorical_accuracy: 0.7030 - lr: 1.0000e-05\nEpoch 20/100\n29/29 [==============================] - ETA: 0s - loss: 0.9817 - accuracy: 0.7791 - top_k_categorical_accuracy: 0.9190\nEpoch 20: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 942ms/step - loss: 0.9817 - accuracy: 0.7791 - top_k_categorical_accuracy: 0.9190 - val_loss: 2.9990 - val_accuracy: 0.4531 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-05\nEpoch 21/100\n29/29 [==============================] - ETA: 0s - loss: 0.9792 - accuracy: 0.7803 - top_k_categorical_accuracy: 0.9193\nEpoch 21: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9792 - accuracy: 0.7803 - top_k_categorical_accuracy: 0.9193 - val_loss: 2.9996 - val_accuracy: 0.4533 - val_top_k_categorical_accuracy: 0.7020 - lr: 1.0000e-06\nEpoch 22/100\n29/29 [==============================] - ETA: 0s - loss: 0.9790 - accuracy: 0.7805 - top_k_categorical_accuracy: 0.9195\nEpoch 22: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 942ms/step - loss: 0.9790 - accuracy: 0.7805 - top_k_categorical_accuracy: 0.9195 - val_loss: 3.0012 - val_accuracy: 0.4538 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-06\nEpoch 23/100\n29/29 [==============================] - ETA: 0s - loss: 0.9788 - accuracy: 0.7805 - top_k_categorical_accuracy: 0.9194\nEpoch 23: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9788 - accuracy: 0.7805 - top_k_categorical_accuracy: 0.9194 - val_loss: 3.0021 - val_accuracy: 0.4536 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-06\nEpoch 24/100\n29/29 [==============================] - ETA: 0s - loss: 0.9785 - accuracy: 0.7805 - top_k_categorical_accuracy: 0.9195\nEpoch 24: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 938ms/step - loss: 0.9785 - accuracy: 0.7805 - top_k_categorical_accuracy: 0.9195 - val_loss: 3.0026 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-06\nEpoch 25/100\n29/29 [==============================] - ETA: 0s - loss: 0.9783 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9195\nEpoch 25: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9783 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9195 - val_loss: 3.0039 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-06\nEpoch 26/100\n29/29 [==============================] - ETA: 0s - loss: 0.9781 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 26: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9781 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0040 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-07\nEpoch 27/100\n29/29 [==============================] - ETA: 0s - loss: 0.9780 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 27: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9780 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0040 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-07\nEpoch 28/100\n29/29 [==============================] - ETA: 0s - loss: 0.9780 - accuracy: 0.7808 - top_k_categorical_accuracy: 0.9196\nEpoch 28: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 943ms/step - loss: 0.9780 - accuracy: 0.7808 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0041 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-07\nEpoch 29/100\n29/29 [==============================] - ETA: 0s - loss: 0.9780 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 29: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 938ms/step - loss: 0.9780 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7016 - lr: 1.0000e-07\nEpoch 30/100\n29/29 [==============================] - ETA: 0s - loss: 0.9780 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 30: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 946ms/step - loss: 0.9780 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-07\nEpoch 31/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 31: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 947ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-08\nEpoch 32/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 32: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 28s 958ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-08\nEpoch 33/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 33: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 947ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-08\nEpoch 34/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 34: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 948ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-08\nEpoch 35/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 35: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 948ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-08\nEpoch 36/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 36: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 947ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-09\nEpoch 37/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 37: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 949ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-09\nEpoch 38/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 38: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 947ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-09\nEpoch 39/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 39: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 948ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-09\nEpoch 40/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 40: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 947ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-09\nEpoch 41/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 41: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 948ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-10\nEpoch 42/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 42: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 949ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-10\nEpoch 43/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 43: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 948ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-10\nEpoch 44/100\n29/29 [==============================] - ETA: 0s - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196\nEpoch 44: val_accuracy did not improve from 0.54070\n29/29 [==============================] - 27s 946ms/step - loss: 0.9779 - accuracy: 0.7807 - top_k_categorical_accuracy: 0.9196 - val_loss: 3.0042 - val_accuracy: 0.4539 - val_top_k_categorical_accuracy: 0.7014 - lr: 1.0000e-10\nEpoch 45/100\n 7/29 [======>.......................] - ETA: 19s - loss: 0.9742 - accuracy: 0.7772 - top_k_categorical_accuracy: 0.9180","output_type":"stream"}]},{"cell_type":"markdown","source":"<b>Plotting the accuracy</b>","metadata":{"id":"5T0mCyLUcRsy"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# plot utility\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n#     plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, string])\n    #     plt.legend([string, 'val_'+string])\n    plt.show()\n\ndef plot_val_graphs(history, string):\n    plt.plot(history.history['val_'+string])\n#     plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel('Validation '+string)\n    #     plt.legend([string, 'val_'+string])\n    plt.show()\n\n# plot the accuracy and results\nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")\n\nplot_val_graphs(history, \"accuracy\")\nplot_val_graphs(history, \"loss\")","metadata":{"id":"NJCM4KdKcRsy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Saving the weights</h2>","metadata":{"id":"8Paj-HDzcRsz"}},{"cell_type":"code","source":"KERAS_MODEL = \"model.h5\"\nTOKENIZER_MODEL = \"tokenizer.pkl\"\n\nmodel.save(KERAS_MODEL)\npickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)","metadata":{"id":"e5td0XUBcRsz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Testing (Error Will Come With GPU, Try Instead Recreating section, without GPU)</h1>","metadata":{"id":"PsN5Z-bscRsz"}},{"cell_type":"code","source":"with strategy.scope():\n    tokenized_test_text = tokenizer.texts_to_sequences([\"EMPHASIS ON USE OF HINDI IN RAILWAYS The Chairman, Railway Board, Shri R.K.Singh ha, the railway department will take stric action on it\"])\n    x_train = keras.preprocessing.sequence.pad_sequences(tokenized_test_text, maxlen=max_sequence_len_tmp)\n    ans = model.predict([x_train])\n\n    flattened = ans.flatten()\n    sorted_indices = np.argsort(-flattened)\n\n    top5_indices = sorted_indices[:5]\n    top5_values = flattened[top5_indices]\n    print(top5_indices)\n    print(\"-------------------\")\n    class_labels = ans.argmax(axis=-1)\n    print(ans)","metadata":{"id":"MxvzZEQQcRsz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(class_labels)","metadata":{"id":"g6hdZa7ocRsz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>For recreating the model from weights, Without gpu, As error is comming in gpu (NO GPU)</h1>\nCancelledError                            Traceback (most recent call last)\nCell In[40], line 4\n      2 tokenized_test_text = tokenizer.texts_to_sequences([\"EMPHASIS ON USE OF HINDI IN RAILWAYS The Chairman, Railway Board, Shri R.K.Singh ha\"])\n      3 x_train = keras.preprocessing.sequence.pad_sequences(tokenized_test_text, maxlen=max_sequence_len_tmp)\n----> 4 ans = model.predict([x_train])\n      5 class_labels = ans.argmax(axis=-1)\n      6 print(ans)\n\nFile /opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)\n     67     filtered_tb = _process_traceback_frames(e.__traceback__)\n     68     # To get the full stack trace, call:\n     69     # `tf.debugging.disable_traceback_filtering()`\n---> 70     raise e.with_traceback(filtered_tb) from None\n     71 finally:\n     72     del filtered_tb\n\nFile /opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     50 try:\n     51   ctx.ensure_initialized()\n---> 52   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     53                                       inputs, attrs, num_outputs)\n     54 except core._NotOkStatusException as e:\n     55   if name is not None:\n\nCancelledError: Graph execution error:\n\nRecvAsync is cancelled.\n\t [[{{node sequential/dense_1/Softmax/_53}}]] [Op:__inference_predict_function_34609]","metadata":{"id":"2TiEZh9OcRsz"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport pandas as pd\nimport numpy as np","metadata":{"id":"nPsn1uVTcRsz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As per last execution during training\nvocab_size = 40310\nmax_sequence_len_tmp = 550\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, 300, input_length=max_sequence_len_tmp),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(61, activation='softmax')\n])","metadata":{"id":"tdxu20sUcRs0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"6posevL6cRs0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>For loading the pretrained model, And making the prediction</h1>","metadata":{"id":"b68CkEeYcRs0"}},{"cell_type":"code","source":"model.load_weights('/kaggle/input/tmp-data/model.h5')","metadata":{"id":"KUj6jAfmcRs0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_tokenizer():\n    with open('/kaggle/input/tmp-data/tokenizer.pkl', 'rb') as handle:\n        tokenizer = pickle.load(handle)\n\n    print(len(tokenizer.word_index))\n    print('loading of tokenizer completed........')\n\n    return tokenizer\n\ntokenizer = load_tokenizer()","metadata":{"id":"Ikf10nEecRs0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_test_text = tokenizer.texts_to_sequences([\"Supreme court gives notice to car owner regarding tax dues\"])\nx_train = keras.preprocessing.sequence.pad_sequences(tokenized_test_text, maxlen=max_sequence_len_tmp)\nans = model.predict([x_train])\nprint(ans)","metadata":{"id":"w9BZiicgcRs1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Finding Top 3 probable minstries as per the model's output</h2>","metadata":{"id":"jt1KQYSPcRs1"}},{"cell_type":"code","source":"# dict_items([('Not Ministry', 61), ('Ministry of Railways', 1), ('Ministry of Rural Development', 2), ('Ministry of Steel', 3), ('Ministry of Science & Technology', 4), ('Ministry of Information & Broadcasting', 5), ('Ministry of Food Processing Industries', 6), ('Ministry of Health and Family Welfare', 7), ('Ministry of Human Resource Development', 8), ('Ministry of Agriculture', 9), ('Ministry of Environment and Forests', 10), ('Ministry of Chemicals and Fertilizers', 11), ('Ministry of Water Resources', 12), ('Ministry of Defence', 13), ('Ministry of Petroleum & Natural Gas', 14), (\"President's Secretariat\", 15), ('Ministry of Micro,Small & Medium Enterprises', 16), ('Ministry of Mines', 17), ('Ministry of Tourism', 18), ('Ministry of Housing & Urban Affairs', 19), ('Ministry of Coal', 20), (\"Prime Minister's Office\", 21), ('Ministry of Textiles', 22), ('Ministry of Commerce & Industry', 23), ('Ministry of External Affairs', 24), ('Ministry of Social Justice & Empowerment', 25), ('Ministry of Power', 26), ('Ministry of Consumer Affairs, Food & Public Distribution', 27), ('Ministry of Heavy Industries & Public Enterprises', 28), ('Ministry of Communications', 29), ('Ministry of Shipping', 30), ('Ministry of Finance', 31), ('Ministry of Tribal Affairs', 32), ('Ministry of Statistics & Programme Implementation', 33), ('Ministry of Labour & Employment', 34), ('Ministry of Law & Justice', 35), (\"Vice President's Secretariat\", 36), ('Ministry of Civil Aviation', 37), ('Ministry for Development of North-East Region', 38), ('UPSC', 39), ('Ministry of Agro & Rural Industries', 40), ('Ministry of Home Affairs', 41), ('Ministry of Youth Affairs and Sports', 42), ('Special Service and Features', 43), ('Ministry of New and Renewable Energy', 44), ('Ministry of Parliamentary Affairs', 45), ('Planning Commission', 46), ('Ministry of Personnel, Public Grievances & Pensions', 47), ('Election Commission', 48), ('Department of Space', 49), ('Ministry of Disinvestment', 50), ('Department of Ocean Development', 51), ('Ministry of Overseas Indian Affairs', 52), ('Ministry of Housing and Urban Poverty Alleviation', 53), ('Ministry of Culture', 54), ('Ministry of Company Affairs', 55), ('Ministry of Panchayati Raj', 56), ('Cabinet Committee on Economic Affairs (CCEA)', 57), ('Cabinet', 58), ('Department of Atomic Energy', 59), ('Cabinet Committee Decisions', 60)])","metadata":{"id":"C-_okeF4cRs1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = ans.argmax(axis=-1)\nprint(class_labels)\ntop_3_labels = np.argsort(ans)[-3:]\nprint(top_3_labels)","metadata":{"id":"2nx8DxU0cRs1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git lfs install","metadata":{"id":"UV04gzgkcRs1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git init","metadata":{"id":"iVIfb0TJcRs1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git status","metadata":{"id":"VN6GH0AFcRs2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  !git config --global user.email \"neeldevenshah@gmail.com\"\n  !git config --global user.name \"Neel Shah\"","metadata":{"id":"qIV9LaHvcRs2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git checkout -b development","metadata":{"id":"cLRG5bCBcRs2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git add --a","metadata":{"id":"g86NusFQcRs2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git commit -m \"Initial commit\"","metadata":{"id":"vgO9rVD6cRs2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git remote add origin https://huggingface.co/neeldevenshah/news_classification_expt1","metadata":{"id":"jOknD7RecRs2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"v4x1-UvRcRs2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"HF_USER\"] = \"neeldevenshah\"\nos.environ[\"HF_TOKEN\"] = \"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\"\n\nfrom huggingface_hub import login\nlogin()","metadata":{"id":"3_L6HavlcRs3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git config --global credential.helper store","metadata":{"id":"tE2LdcepcRs3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git push origin development","metadata":{"id":"qjYQD5pZcRs3","trusted":true},"execution_count":null,"outputs":[]}]}