{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.crawler import CrawlerProcess\n",
    "import scrapy\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "\n",
    "class NewsSpider(scrapy.Spider):\n",
    "    name = 'news'\n",
    "    start_urls = [\n",
    "        'https://timesofindia.indiatimes.com/',\n",
    "        'https://indianexpress.com/',\n",
    "        'https://www.hindustantimes.com/',\n",
    "        'https://www.thehindu.com/',\n",
    "        'https://www.deccanherald.com/',\n",
    "        'https://www.telegraphindia.com/',\n",
    "        'https://www.newindianexpress.com/',\n",
    "        'https://www.thequint.com/',\n",
    "        'https://www.livemint.com/',\n",
    "        'https://www.financialexpress.com/',\n",
    "        'https://www.business-standard.com/',\n",
    "        'https://www.firstpost.com/',\n",
    "        'https://www.outlookindia.com/',\n",
    "        'https://www.indiatoday.in/',\n",
    "        'https://www.theweek.in/',\n",
    "        'https://www.dnaindia.com/',\n",
    "        'https://www.freepressjournal.in/',\n",
    "        'https://www.thestatesman.com/',\n",
    "        'https://www.tribuneindia.com/',\n",
    "        'https://www.mid-day.com/'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        if 'timesofindia' in response.url:\n",
    "            yield from self.parse_times_of_india(response)\n",
    "        elif 'indianexpress' in response.url:\n",
    "            yield from self.parse_indian_express(response)\n",
    "        elif 'hindustantimes' in response.url:\n",
    "            yield from self.parse_hindustan_times(response)\n",
    "        elif 'thehindu' in response.url:\n",
    "            yield from self.parse_the_hindu(response)\n",
    "        elif 'deccanherald' in response.url:\n",
    "            yield from self.parse_deccan_herald(response)\n",
    "        elif 'telegraphindia' in response.url:\n",
    "            yield from self.parse_telegraph_india(response)\n",
    "        elif 'newindianexpress' in response.url:\n",
    "            yield from self.parse_new_indian_express(response)\n",
    "        elif 'thequint' in response.url:\n",
    "            yield from self.parse_the_quint(response)\n",
    "        elif 'livemint' in response.url:\n",
    "            yield from self.parse_livemint(response)\n",
    "        elif 'financialexpress' in response.url:\n",
    "            yield from self.parse_financial_express(response)\n",
    "        elif 'business-standard' in response.url:\n",
    "            yield from self.parse_business_standard(response)\n",
    "        elif 'firstpost' in response.url:\n",
    "            yield from self.parse_firstpost(response)\n",
    "        elif 'outlookindia' in response.url:\n",
    "            yield from self.parse_outlook_india(response)\n",
    "        elif 'indiatoday' in response.url:\n",
    "            yield from self.parse_indiatoday(response)\n",
    "        elif 'theweek' in response.url:\n",
    "            yield from self.parse_the_week(response)\n",
    "        elif 'dnaindia' in response.url:\n",
    "            yield from self.parse_dnaindia(response)\n",
    "        elif 'freepressjournal' in response.url:\n",
    "            yield from self.parse_freepressjournal(response)\n",
    "        elif 'thestatesman' in response.url:\n",
    "            yield from self.parse_thestatesman(response)\n",
    "        elif 'tribuneindia' in response.url:\n",
    "            yield from self.parse_tribuneindia(response)\n",
    "        elif 'mid-day' in response.url:\n",
    "            yield from self.parse_mid_day(response)\n",
    "\n",
    "    def parse_times_of_india(self, response):\n",
    "        # Implement parsing logic for Times of India\n",
    "        articles = response.css('a[href*=\"/india/\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_indian_express(self, response):\n",
    "        # Implement parsing logic for Indian Express\n",
    "        articles = response.css('h3 a::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_hindustan_times(self, response):\n",
    "        # Implement parsing logic for Hindustan Times\n",
    "        articles = response.css('a::attr(href)').re(\n",
    "            r'\\/[^\\/]+\\/[^\\/]+\\/\\d+\\/\\d+\\.html')\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_the_hindu(self, response):\n",
    "        # Implement parsing logic for The Hindu\n",
    "        articles = response.css('a.story-card75x1-text::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_deccan_herald(self, response):\n",
    "        # Implement parsing logic for Deccan Herald\n",
    "        articles = response.css(\n",
    "            'a[id*=\"block-system-main\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_telegraph_india(self, response):\n",
    "        # Implement parsing logic for The Telegraph India\n",
    "        articles = response.css('a[href*=\"/calcutta/\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_new_indian_express(self, response):\n",
    "        # Implement parsing logic for New Indian Express\n",
    "        articles = response.css('h3 a::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_the_quint(self, response):\n",
    "        # Implement parsing logic for The Quint\n",
    "        articles = response.css('a.card-heading::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_livemint(self, response):\n",
    "        # Implement parsing logic for Live Mint\n",
    "        articles = response.css('a[id*=\"a_title\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_financial_express(self, response):\n",
    "        # Implement parsing logic for Financial Express\n",
    "        articles = response.css('a.headline::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_business_standard(self, response):\n",
    "        # Implement parsing logic for Business Standard\n",
    "        articles = response.css('a.readmore-link::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_firstpost(self, response):\n",
    "        # Implement parsing logic for Firstpost\n",
    "        articles = response.css('a.article-title::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_outlook_india(self, response):\n",
    "        # Implement parsing logic for Outlook India\n",
    "        articles = response.css('a[id*=\"morenews\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_indiatoday(self, response):\n",
    "        # Implement parsing logic for India Today\n",
    "        articles = response.css('a[id*=\"story-\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_the_week(self, response):\n",
    "        # Implement parsing logic for The Week\n",
    "        articles = response.css('a[class*=\"storyLink\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_dnaindia(self, response):\n",
    "        # Implement parsing logic for DNA India\n",
    "        articles = response.css('a[href*=\"/news/\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_freepressjournal(self, response):\n",
    "        # Implement parsing logic for Free Press Journal\n",
    "        articles = response.css(\n",
    "            'a[href*=\"/freepressjournal/\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_thestatesman(self, response):\n",
    "        # Implement parsing logic for The Statesman\n",
    "        articles = response.css(\n",
    "            'a[href*=\"/statesmannews/\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_tribuneindia(self, response):\n",
    "        # Implement parsing logic for Tribune India\n",
    "        articles = response.css('a[class*=\"hlheading\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_mid_day(self, response):\n",
    "        # Implement parsing logic for Mid-Day\n",
    "        articles = response.css('a[class*=\"headline1\"]::attr(href)').extract()\n",
    "        for article in articles:\n",
    "            yield response.follow(article, self.parse_article)\n",
    "\n",
    "    def parse_article(self, response):\n",
    "        # Extract title and text from the article page\n",
    "        title = response.css('title::text').get()\n",
    "        text = ''.join(response.css('p::text').extract())\n",
    "\n",
    "        yield {\n",
    "            'Title': title,\n",
    "            'Text': text,\n",
    "            'Source URL': response.url,\n",
    "        }\n",
    "\n",
    "\n",
    "def get_news():\n",
    "\n",
    "    spider = NewsSpider()\n",
    "\n",
    "    process = CrawlerProcess(settings={\n",
    "        'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'FEED_FORMAT': 'json',\n",
    "        'FEED_URI': './tmp/news_data.json',  # Specify the output file for scraped data\n",
    "        'LOG_LEVEL': 'INFO',  # Adjust the log level as needed\n",
    "    })\n",
    "\n",
    "    # Start the spider and scraping process\n",
    "    process.crawl(NewsSpider)\n",
    "    process.start()\n",
    "\n",
    "    scraped_data = pd.read_json('./tmp/news_data.json')\n",
    "    subprocess.run([\"rm\", \"./tmp/news_data.json\"],\n",
    "                   capture_output=True)\n",
    "\n",
    "    return scraped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 21:46:05 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: scrapybot)\n",
      "2023-09-21 21:46:05 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.3 19 Sep 2023), cryptography 41.0.4, Platform Linux-6.0.12-76060006-generic-x86_64-with-glibc2.35\n",
      "2023-09-21 21:46:05 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-09-21 21:46:05 [py.warnings] WARNING: /home/neel/anaconda3/envs/sample_env/lib/python3.11/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-09-21 21:46:05 [scrapy.extensions.telnet] INFO: Telnet Password: b2c6a12224205341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 21:46:05 [py.warnings] WARNING: /home/neel/anaconda3/envs/sample_env/lib/python3.11/site-packages/scrapy/extensions/feedexport.py:406: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n",
      "2023-09-21 21:46:05 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-09-21 21:46:05 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 'INFO',\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
      "               '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
      "2023-09-21 21:46:05 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-09-21 21:46:05 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-09-21 21:46:05 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-09-21 21:46:05 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-09-21 21:46:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-09-21 21:46:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6030\n",
      "2023-09-21 21:46:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://www.outlookindia.com/>: HTTP status code is not handled or not allowed\n",
      "2023-09-21 21:46:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://www.tribuneindia.com/>: HTTP status code is not handled or not allowed\n",
      "2023-09-21 21:46:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://www.thestatesman.com/>: HTTP status code is not handled or not allowed\n",
      "2023-09-21 21:46:54 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-09-21 21:46:54 [scrapy.extensions.feedexport] INFO: Stored json feed (101 items) in: ./tmp/news_data.json\n",
      "2023-09-21 21:46:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 133490,\n",
      " 'downloader/request_count': 122,\n",
      " 'downloader/request_method_count/GET': 122,\n",
      " 'downloader/response_bytes': 9403791,\n",
      " 'downloader/response_count': 122,\n",
      " 'downloader/response_status_count/200': 118,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'downloader/response_status_count/403': 3,\n",
      " 'dupefilter/filtered': 10,\n",
      " 'elapsed_time_seconds': 49.441592,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 9, 21, 16, 16, 54, 729305, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 51152166,\n",
      " 'httpcompression/response_count': 121,\n",
      " 'httperror/response_ignored_count': 3,\n",
      " 'httperror/response_ignored_status_count/403': 3,\n",
      " 'item_scraped_count': 101,\n",
      " 'log_count/INFO': 14,\n",
      " 'log_count/WARNING': 2,\n",
      " 'memusage/max': 146948096,\n",
      " 'memusage/startup': 146948096,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 121,\n",
      " 'scheduler/dequeued': 122,\n",
      " 'scheduler/dequeued/memory': 122,\n",
      " 'scheduler/enqueued': 122,\n",
      " 'scheduler/enqueued/memory': 122,\n",
      " 'start_time': datetime.datetime(2023, 9, 21, 16, 16, 5, 287713, tzinfo=datetime.timezone.utc)}\n",
      "2023-09-21 21:46:54 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Manipur, efforts to storm several police st...</td>\n",
       "      <td>Protests in Manipur’s valley pressing for the ...</td>\n",
       "      <td>https://indianexpress.com/article/india/in-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Values Kota imparted: Anxiety and building a f...</td>\n",
       "      <td>I have never been to Kota. In the many train j...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asha Bhosle’s 90th birthday: In Umrao Jaan, he...</td>\n",
       "      <td>Some sacred voices are made in heaven, those w...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women’s reservation Bill – imperfect but impor...</td>\n",
       "      <td>The introduction of the Constitution (One Hund...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lifestyle: Latest Lifestyle News, Fashion Tren...</td>\n",
       "      <td>\"Loved the result of glass-like skin. It's so ...</td>\n",
       "      <td>https://indianexpress.com/section/lifestyle/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jaane Jaan movie review: Kareena Kapoor is bot...</td>\n",
       "      <td>The discovery of a horrifically mutilated body...</td>\n",
       "      <td>https://indianexpress.com/article/entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Diplomatic tensions: Trade relations, and Indi...</td>\n",
       "      <td>Diplomatic tensions between New Delhi and Otta...</td>\n",
       "      <td>https://indianexpress.com/article/explained/ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Invoking her father Rajiv, Priyanka says rules...</td>\n",
       "      <td>Congress general secretary Priyanka Gandhi, du...</td>\n",
       "      <td>https://indianexpress.com/article/india/rajiv-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Canada PM Justin Trudeau refused to stay at De...</td>\n",
       "      <td>Canada Prime Minister Justin Trudeau’s securit...</td>\n",
       "      <td>https://indianexpress.com/article/cities/delhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Himachal-Pradesh News, Latest Himachal-Pradesh...</td>\n",
       "      <td>You must login to keep earning daily check-in ...</td>\n",
       "      <td>https://timesofindia.indiatimes.com/india/hima...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    In Manipur, efforts to storm several police st...   \n",
       "1    Values Kota imparted: Anxiety and building a f...   \n",
       "2    Asha Bhosle’s 90th birthday: In Umrao Jaan, he...   \n",
       "3    Women’s reservation Bill – imperfect but impor...   \n",
       "4    Lifestyle: Latest Lifestyle News, Fashion Tren...   \n",
       "..                                                 ...   \n",
       "96   Jaane Jaan movie review: Kareena Kapoor is bot...   \n",
       "97   Diplomatic tensions: Trade relations, and Indi...   \n",
       "98   Invoking her father Rajiv, Priyanka says rules...   \n",
       "99   Canada PM Justin Trudeau refused to stay at De...   \n",
       "100  Himachal-Pradesh News, Latest Himachal-Pradesh...   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    Protests in Manipur’s valley pressing for the ...   \n",
       "1    I have never been to Kota. In the many train j...   \n",
       "2    Some sacred voices are made in heaven, those w...   \n",
       "3    The introduction of the Constitution (One Hund...   \n",
       "4    \"Loved the result of glass-like skin. It's so ...   \n",
       "..                                                 ...   \n",
       "96   The discovery of a horrifically mutilated body...   \n",
       "97   Diplomatic tensions between New Delhi and Otta...   \n",
       "98   Congress general secretary Priyanka Gandhi, du...   \n",
       "99   Canada Prime Minister Justin Trudeau’s securit...   \n",
       "100  You must login to keep earning daily check-in ...   \n",
       "\n",
       "                                            Source URL  \n",
       "0    https://indianexpress.com/article/india/in-man...  \n",
       "1    https://indianexpress.com/article/opinion/colu...  \n",
       "2    https://indianexpress.com/article/opinion/colu...  \n",
       "3    https://indianexpress.com/article/opinion/colu...  \n",
       "4         https://indianexpress.com/section/lifestyle/  \n",
       "..                                                 ...  \n",
       "96   https://indianexpress.com/article/entertainmen...  \n",
       "97   https://indianexpress.com/article/explained/ev...  \n",
       "98   https://indianexpress.com/article/india/rajiv-...  \n",
       "99   https://indianexpress.com/article/cities/delhi...  \n",
       "100  https://timesofindia.indiatimes.com/india/hima...  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
